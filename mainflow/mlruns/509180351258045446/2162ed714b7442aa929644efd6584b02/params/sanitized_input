{'recent advances in deep neural network architectures and optimization methods': [{'title': 'Effective, Efficient and Robust Neural Architecture Search', 'authors': 'Zhixiong Yue, Baijiong Lin, Xiaonan Huang, Yu Zhang', 'abstract': 'Recent advances in adversarial attacks show the vulnerability of deep neural networks searched by Neural Architecture Search (NAS). Although NAS methods can find network architectures with the state-of-the-art performance, the adversarial robustness and resource constraint are often ignored in NAS. To solve this problem, we propose an Effective, Efficient, and Robust Neural Architecture Search (E2RNAS) method to search a neural network architecture by taking the performance, robustness, and resource constraint into consideration. The objective function of the proposed E2RNAS method is formulated as a bi-level multi-objective optimization problem with the upper-level problem as a multi-objective optimization problem, which is different from existing NAS methods. To solve the proposed objective function, we integrate the multiple-gradient descent algorithm, a widely studied gradient-based multi-objective optimization algorithm, with the bi-level optimization. Experiments on benchmark datasets show that the proposed E2RNAS method can find adversarially robust architectures with optimized model size and comparable classification accuracy.', 'year': 2020, 'link': 'http://arxiv.org/abs/2011.09820v1'}], 'overfitting, underfitting, and generalization in machine learning theory': [{'title': 'An Information-Theoretic Perspective on Overfitting and Underfitting', 'authors': 'Daniel Bashir, George D. Montanez, Sonia Sehra, Pedro Sandoval Segura, Julius Lauw', 'abstract': 'We present an information-theoretic framework for understanding overfitting and underfitting in machine learning and prove the formal undecidability of determining whether an arbitrary classification algorithm will overfit a dataset. Measuring algorithm capacity via the information transferred from datasets to models, we consider mismatches between algorithm capacities and datasets to provide a signature for when a model can overfit or underfit a dataset. We present results upper-bounding algorithm capacity, establish its relationship to quantities in the algorithmic search framework for machine learning, and relate our work to recent information-theoretic approaches to generalization.', 'year': 2020, 'link': 'http://arxiv.org/abs/2010.06076v2'}], 'algorithmic fairness, bias mitigation, and responsible AI in data ethics': [{'title': 'Responsible Design Patterns for Machine Learning Pipelines', 'authors': 'Saud Hakem Al Harbi, Lionel Nganyewou Tidjon, Foutse Khomh', 'abstract': 'Integrating ethical practices into the AI development process for artificial intelligence (AI) is essential to ensure safe, fair, and responsible operation. AI ethics involves applying ethical principles to the entire life cycle of AI systems. This is essential to mitigate potential risks and harms associated with AI, such as algorithm biases. To achieve this goal, responsible design patterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee ethical and fair outcomes. In this paper, we propose a comprehensive framework incorporating RDPs into ML pipelines to mitigate risks and ensure the ethical development of AI systems. Our framework comprises new responsible AI design patterns for ML pipelines identified through a survey of AI ethics and data management experts and validated through real-world scenarios with expert feedback. The framework guides AI developers, data scientists, and policy-makers to implement ethical practices in AI development and deploy responsible AI systems in production.', 'year': 2023, 'link': 'http://arxiv.org/abs/2306.01788v3'}], 'data preprocessing and feature engineering techniques for high-quality machine learning datasets': [{'title': 'DPASF: A Flink Library for Streaming Data preprocessing', 'authors': 'Alejandro Alcalde-Barros, Diego García-Gil, Salvador García, Francisco Herrera', 'abstract': 'Data preprocessing techniques are devoted to correct or alleviate errors in data. Discretization and feature selection are two of the most extended data preprocessing techniques. Although we can find many proposals for static Big Data preprocessing, there is little research devoted to the continuous Big Data problem. Apache Flink is a recent and novel Big Data framework, following the MapReduce paradigm, focused on distributed stream and batch data processing. In this paper we propose a data stream library for Big Data preprocessing, named DPASF, under Apache Flink. We have implemented six of the most popular data preprocessing algorithms, three for discretization and the rest for feature selection. The algorithms have been tested using two Big Data datasets. Experimental results show that preprocessing can not only reduce the size of the data, but to maintain or even improve the original accuracy in a short time. DPASF contains useful algorithms when dealing with Big Data data streams. The preprocessing algorithms included in the library are able to tackle Big Datasets efficiently and to correct imperfections in the data.', 'year': 2018, 'link': 'http://arxiv.org/abs/1810.06021v1'}], 'comparative analysis of supervised, unsupervised, and reinforcement learning paradigms': [{'title': 'URLB: Unsupervised Reinforcement Learning Benchmark', 'authors': 'Michael Laskin, Denis Yarats, Hao Liu, Kimin Lee, Albert Zhan, Kevin Lu, Catherine Cang, Lerrel Pinto, Pieter Abbeel', 'abstract': 'Deep Reinforcement Learning (RL) has emerged as a powerful paradigm to solve a range of complex yet specific control tasks. Yet training generalist agents that can quickly adapt to new tasks remains an outstanding challenge. Recent advances in unsupervised RL have shown that pre-training RL agents with self-supervised intrinsic rewards can result in efficient adaptation. However, these algorithms have been hard to