import streamlit as st
import sys
from pathlib import Path
import time
import mlflow
import pandas as pd
from mlflow.genai.scorers import RelevanceToQuery
from mlflow.genai.judges import custom_prompt_judge
from mlflow.genai.scorers import scorer
from frontend.utils.style_manager import apply_custom_styles

src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

mlflow.set_experiment("EY Junior Accelerator")

from mainflow.main import Flow, State
from mainflow.utils.input_validation import is_valid_input
from mainflow.crews.input_crew.input_validation_crew import InputValidationCrew
from mainflow.crews.planner_crew.crew import PlanningCrew
from mainflow.crews.web_crew.crew_new import WebCrew
from mainflow.crews.paper_crew.paper_crew import PaperCrew
from mainflow.crews.study_plan_crew.crew import FinalStudyPlanCrew
from mainflow.crews.calendar_crew.crew import CalendarCrew
from crewai.flow import Flow as CrewAIFlow, listen, start, router

@scorer
def evaluate_search_quality(inputs, outputs):
    """
    Evaluates the relevance of retrieved documents to the user's query.
    
    Args:
        inputs: Dictionary containing the original user query
        outputs: Dictionary containing the retrieved documents
    
    Returns:
        Numeric score representing relevance (0.0 to 10.0)
    """
    relevance_prompt = """
    Assess the relevance of the following documents to the user's query. 
    Consider how well the documents address the user's intent and provide useful information.

    You must choose one of the following categories:

    [[highly_relevant]]: The documents are directly related to the user's query, providing comprehensive and accurate information that fully addresses the user's needs.

    [[somewhat_relevant]]: The documents are generally related to the user's query but may lack depth or miss some aspects of the user's intent. They provide useful information but could be improved.

    [[not_relevant]]: The documents do not adequately address the user's query. They may be off-topic, too vague, or fail to provide useful information.

    User query: {{input_query}}
    Retrieved documents: {{output_documents}}
    """
    relevance_judge = custom_prompt_judge(
        name="search_relevance_evaluator",
        prompt_template=relevance_prompt,
        model="azure:/gpt-4.1",
        numeric_values={
            "highly_relevant": 10.0,
            "somewhat_relevant": 5.0,
            "not_relevant": 0.0,
        },
    )
    return relevance_judge(input_query=inputs, output_documents=outputs)

@scorer
def evaluate_study_plan_quality(inputs, outputs):
    """
    Evaluates the quality of a study plan generated by CrewAI agents
    
    Args:
        inputs: Dictionary containing student request and context
        outputs: Dictionary containing the generated study plan
    
    Returns:
        Numeric score representing plan quality (0.0 to 1.0)
    """
    study_planning_prompt = """
    Evaluate the quality and effectiveness of a study plan created by an AI agent. 
    Assess how well the plan addresses the student's learning objectives, timeline, and educational needs.

    You must choose one of the following categories:

    [[excellent_plan]]: The study plan is comprehensive, well-structured, realistic, and perfectly tailored to the student's needs. It includes:
    - Clear learning objectives and milestones
    - Appropriate time allocation and realistic scheduling
    - Varied study methods and resources
    - Assessment checkpoints and progress tracking
    - Consideration of student's current level and constraints

    [[good_plan]]: The study plan is solid and helpful but may lack some detail or optimization. It addresses most requirements but could be enhanced with:
    - Better time management or pacing
    - More diverse learning resources
    - Clearer milestone definitions
    - Minor adjustments for student's specific needs

    [[poor_plan]]: The study plan is inadequate, unrealistic, or doesn't address the student's requirements:
    - Vague or missing objectives
    - Poor time allocation or unrealistic expectations
    - Lack of structured approach
    - Ignores student's constraints or level
    Study plan: {{input_plan}}
    Generated study plan: {{output_plan}}
    """
    study_plan_judge = custom_prompt_judge(
        name="study_plan_evaluator",
        prompt_template=study_planning_prompt,
        model="azure:/gpt-4.1",
        numeric_values={
            "excellent_plan": 10.0,
            "good_plan": 7.5,
            "poor_plan": 2.5,
        },
    )
    return study_plan_judge(input_plan=inputs, output_plan=outputs)

class MonitoringConfig:
    """Configuration class for monitoring CrewAI operations with MLflow"""
    
    def __init__(self):
        self.start_time = time.time()

    def monitoring_crew(self, state, crew_output, crew, crew_name):
        """
        Enhanced monitoring that works alongside CrewAI autolog.
        Autolog will handle detailed agent/task tracing, while this provides workflow-level metrics.
        """
        with mlflow.start_run(run_name=f"{crew_name} Monitoring", nested=True):              
            mlflow.log_param("crew", crew_name)
            mlflow.log_param("input_question", state.question)
            mlflow.log_param("sanitized_input", crew_output.raw)
            mlflow.log_param("num_agents", len(crew.agents))
            execution_time = time.time() - self.start_time
            mlflow.log_metric("execution_time_seconds", round(execution_time, 2))
            mlflow.log_param("output_type", type(crew_output).__name__)
            mlflow.log_metric("output_length", len(str(crew_output.raw)))
            mlflow.log_metric("tokens_total", float(crew_output.token_usage.total_tokens))
            mlflow.log_metric("tokens_prompt", float(len(state.question)))
            mlflow.log_metric("tokens_completion", float(crew_output.token_usage.completion_tokens))
            mlflow.log_param("token_usage_details", str(crew_output.token_usage))

            # Prezzo GPT 4.1 per 1M token
                # ‚Ç¨1.73 input
                # ‚Ç¨6.91 output
            # Prezzo GPT 4.1 mini per 1M token
                # ‚Ç¨0.35 input
                # ‚Ç¨1.39 output
            mlflow.log_metric("input_prompt_cost_estimate_eur", round(crew_output.token_usage.total_tokens * 0.00000173, 6))
            mlflow.log_metric("output_completion_cost_estimate_eur", round(crew_output.token_usage.completion_tokens * 0.00000691, 6))
            mlflow.log_metric("total_cost_estimate_eur", round(crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691, 6))  
            
            if crew_name == "PlanningCrew":
                feedback = evaluate_study_plan_quality(state.user_info, crew_output.raw)
                mlflow.log_metric("study_plan_quality_score", feedback.value)
                mlflow.log_param("study_plan_quality_feedback", feedback.rationale)
            if crew_name == "WebCrew":
                feedback = evaluate_search_quality(state.plan, crew_output.raw)
                mlflow.log_metric("search_relevance_score", feedback.value)
                mlflow.log_param("search_relevance_feedback", feedback.rationale)

class StreamlitFlow(CrewAIFlow[State]):
    """Custom Flow for Streamlit that accepts user input directly with MLflow monitoring"""
    
    def __init__(self, user_input: str, progress_callback=None, status_callback=None):
        super().__init__()
        self.user_input = user_input
        self.progress_callback = progress_callback
        self.status_callback = status_callback
        self.monitor = MonitoringConfig()
        self.workflow_start_time = time.time()
        self.total_token_count = 0
        self.total_cost = 0
        
    @start()
    def insert_topic(self):
        print("="*20, " Welcome to the EY Junior Accelerator! ", "="*20)
        
        if not is_valid_input(self.user_input):
            print("Invalid input detected. Please avoid using escape sequences or empty inputs.")
            raise ValueError("Invalid input provided")
            
        self.state.question = self.user_input

    @listen(insert_topic)
    def sanitize_input(self):
        if self.status_callback:
            self.status_callback("Sanitizing input...")
        if self.progress_callback:
            self.progress_callback(0.2)
            
        print("Sanitizing input")
        validation_crew = InputValidationCrew()
        crew_output = validation_crew.crew().kickoff(
            inputs={"question": self.state.question}
        )
        
        self.monitor.monitoring_crew(self.state, crew_output, validation_crew.crew(), "InputValidationCrew")

        self.total_token_count += crew_output.token_usage.total_tokens
        self.total_cost += (crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691)

        print(crew_output.raw)
        self.state.user_info = crew_output.raw

    @router(sanitize_input)
    def routing(self):
        if "error" in self.state.user_info.lower():
            #return "insert_topic"
            return "insert_topic"
        else:
            return "plan_generate"

    @listen("plan_generate")
    def generate_plan(self):
        if self.status_callback:
            self.status_callback("Generating study plan outline...")
        if self.progress_callback:
            self.progress_callback(0.35)
            
        print("Generating plan")
        planning_crew = PlanningCrew()
        crew_output = planning_crew.crew().kickoff(
            inputs={"user_info": self.state.user_info}
        )
        
        self.monitor.monitoring_crew(self.state, crew_output, planning_crew.crew(), "PlanningCrew")

        self.total_token_count += crew_output.token_usage.total_tokens
        self.total_cost += (crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691)
        
        print("Plan output:", crew_output.raw)
        self.state.plan = crew_output.raw

    @listen(generate_plan)
    def web_search(self):
        if self.status_callback:
            self.status_callback("Searching for web resources...")
        if self.progress_callback:
            self.progress_callback(0.5)
            
        print("Searching the web for resources")
        web_crew = WebCrew()
        crew_output = web_crew.crew().kickoff(
            inputs={"plan": self.state.plan}
        )
        
        self.monitor.monitoring_crew(self.state, crew_output, web_crew.crew(), "WebCrew")

        self.total_token_count += crew_output.token_usage.total_tokens
        self.total_cost += (crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691)
        
        print("Web crew output:", crew_output.raw)
        self.state.resources = crew_output.raw

    @listen(web_search)
    def paper_research(self):
        if self.status_callback:
            self.status_callback("Researching academic papers...")
        if self.progress_callback:
            self.progress_callback(0.65)
            
        print("Searching for academic papers")
        paper_crew = PaperCrew()
        crew_output = paper_crew.crew().kickoff(
            inputs={"plan": self.state.plan}
        )
        
        self.monitor.monitoring_crew(self.state, crew_output, paper_crew.crew(), "PaperCrew")

        self.total_token_count += crew_output.token_usage.total_tokens
        self.total_cost += (crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691)
        
        print("Papers crew output:", crew_output.raw)
        self.state.papers = crew_output.raw

    @listen(paper_research)
    def define_calendar(self):
        if self.status_callback:
            self.status_callback("Creating study calendar...")
        if self.progress_callback:
            self.progress_callback(0.8)
            
        print("Defining calendar")
        calendar_crew = CalendarCrew()
        crew_output = calendar_crew.crew().kickoff(
            inputs={
                "web_resources": self.state.resources,
                "papers": self.state.papers,
                "plan": self.state.plan
            }
        )
        
        self.monitor.monitoring_crew(self.state, crew_output, calendar_crew.crew(), "CalendarCrew")

        self.total_token_count += crew_output.token_usage.total_tokens
        self.total_cost += (crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691)
        
        print("Calendar defined based on the plan, resources, and papers.")
        self.state.calendar = crew_output.raw

    @listen(define_calendar)
    def create_study_plan(self):
        if self.status_callback:
            self.status_callback("Finalizing your personalized study plan...")
        if self.progress_callback:
            self.progress_callback(0.95)
            
        print("Creating study plan")
        study_plan_crew = FinalStudyPlanCrew()
        crew_output = study_plan_crew.crew().kickoff(
            inputs={
                "resources": self.state.resources,
                "papers": self.state.papers,
                "plan": self.state.plan,
                "calendar": self.state.calendar
            }
        )
        
        self.monitor.monitoring_crew(self.state, crew_output, study_plan_crew.crew(), "FinalStudyPlanCrew")
        
        evaluation_ethics_data = pd.DataFrame([{"inputs": {"question": self.state.question},
                                                "outputs": crew_output.raw}])
        mlflow.genai.evaluate(data=evaluation_ethics_data, scorers=[RelevanceToQuery(model="azure:/gpt-4.1")])

        self.total_token_count += crew_output.token_usage.total_tokens
        self.total_cost += (crew_output.token_usage.total_tokens * 0.00000173 + crew_output.token_usage.completion_tokens * 0.00000691)
        
        print(crew_output.raw)
        self.state.study_plan = crew_output.raw

def main():
    """Main Streamlit application"""
    
    # Page configuration
    st.set_page_config(
        page_title="Junior Accelerator",
        page_icon="",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    if 'disclaimer_accepted' not in st.session_state:
        st.session_state.disclaimer_accepted = False
    
    if not st.session_state.disclaimer_accepted:
        @st.dialog("AI-Powered System Notice")
        def show_disclaimer():
            st.warning("**Important Notice**")
            st.markdown("""
            **This system uses artificial intelligence to generate personalized study guides based on your input.**
            
            Please note that:
            - **No human is involved** in the generation of these responses
            - This system is powered by **AI (GPT-4.1)** 
            - **Responses are automatically generated**
            - Results should be reviewed and validated independently
            
            By continuing, you acknowledge and accept these terms.
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("I Understand & Continue", use_container_width=True, type="primary"):
                    st.session_state.disclaimer_accepted = True
                    st.rerun()
            with col2:
                if st.button("Cancel", use_container_width=True):
                    st.stop()
        
        show_disclaimer()
        return
    
    apply_custom_styles()
    
    # Header layout with logo on the left and title
    header_col1, header_col2 = st.columns([0.3, 4])
    with header_col1:
        st.image("./frontend/pics/image-removebg-preview.png", width=120)
    with header_col2:
        st.title("EY Junior Accelerator")
        st.markdown("### Your AI-Powered Learning Plan Generator")
    
    st.markdown("---")
    
    with st.form("user_input_form", clear_on_submit=False):
        user_input = st.text_area(
            "Please describe your background and learning goals:",
            placeholder="Example: I'm a finance professional with a bachelor's degree in economics. I want to become proficient in AI and machine learning to transition into an AI Engineer role.",
            height=100,
            help="Be specific about your background, current role, and what you want to learn",
            key="user_input_text"
        )
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            submit_button = st.form_submit_button("Generate My Study Plan", use_container_width=True)
        
    if submit_button and user_input:
        with st.spinner("Generating learning plan..."):
            try:
                with mlflow.start_run(run_name="Streamlit_EYFlow_with_Autolog") as run:
                    mlflow.crewai.autolog()
                    mlflow.log_param("workflow_type", "EY_Junior_Accelerator")
                    mlflow.log_param("interface", "streamlit")
                    mlflow.log_param("user_input", user_input[:200] + "..." if len(user_input) > 200 else user_input)
                    
                    st.markdown("###  Generation Progress")
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def update_progress(progress_value):
                        progress_bar.progress(progress_value)
                    
                    def update_status(status_message):
                        status_text.text(status_message)
                    
                    flow = StreamlitFlow(
                        user_input=user_input,
                        progress_callback=update_progress,
                        status_callback=update_status
                    )
                    
                    update_status("Starting AI agents...")
                    update_progress(0.1)
                    
                    workflow_start_time = time.time()
                    
                    flow.kickoff()
                    
                    update_progress(1.0)
                    update_status("Study plan generated successfully!")
                    
                    total_workflow_time = time.time() - workflow_start_time
                    mlflow.log_metric("total_workflow_time", total_workflow_time)
                    mlflow.log_param("workflow_status", "completed")
                    
                    result = {
                        "study_plan": flow.state.study_plan,
                        "resources": flow.state.resources, 
                        "papers": flow.state.papers,
                        "plan": flow.state.plan,
                        "calendar": flow.state.calendar
                    }
                    
                    mlflow.log_metric("final_study_plan_length", len(result.get("study_plan", "")))
                    mlflow.log_metric("resources_length", len(result.get("resources", "")))
                    mlflow.log_metric("papers_length", len(result.get("papers", "")))

                    total_token_count = flow.total_token_count
                    total_cost = flow.total_cost

                    mlflow.log_metric("total_token_count", total_token_count)
                    mlflow.log_metric("total_cost", total_cost)

                    print(f"üéâ Workflow completed successfully in {total_workflow_time:.2f} seconds")
                
                
                # Display final result
                if result and result.get("study_plan"):
                    st.success(" Your personalized study plan is ready!")
                    
                    # Display the final study plan
                    st.markdown("Your Complete Study Plan")
                        
                    # Display additional sections in tabs
                    tab1, tab2, tab3, tab4 = st.tabs([" Web Resources", " Academic Papers", " Learning Plan", " Calendar"])

                    with tab1:
                        if result.get("resources"):
                            st.markdown(result["resources"])
                        else:
                            st.info("No web resources found.")
                            
                    with tab2:
                        if result.get("papers"):
                            st.markdown(result["papers"])
                        else:
                            st.info("No academic papers found.")
                            
                    with tab3:
                        if result.get("plan"):
                            st.markdown(result["plan"])
                        else:
                            st.info("No detailed plan available.")
                            
                    with tab4:
                        if result.get("calendar"):
                            st.markdown(result["calendar"])
                        else:
                            st.info("No calendar available.")
                            
                    st.markdown("---")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.download_button(
                            label=" Download Study Plan",
                            data=result.get("study_plan", ""),
                            file_name="my_study_plan.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                    
                    with col2:
                        st.download_button(
                            label=" Download Resources",
                            data=result.get("resources", ""),
                            file_name="learning_resources.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                    
                    with col3:
                        st.download_button(
                            label=" Download Papers",
                            data=result.get("papers", ""),
                            file_name="academic_papers.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                    
                    with col4:
                        st.download_button(
                            label=" Download Calendar",
                            data=result.get("calendar", ""),
                            file_name="study_calendar.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                else:
                    st.error(" Could not generate study plan. Please try again.")
                    
            except Exception as e:
                if 'run' in locals():
                    mlflow.log_param("workflow_status", "failed")
                    mlflow.log_param("error_message", str(e))
                
                st.error(f" An error occurred: {str(e)}")
                with st.expander(" Error Details", expanded=False):
                    st.code(str(e))
                st.info(" Please try rephrasing your request or contact support if the issue persists.")
                print(f"‚ùå Workflow failed: {e}")
    
    elif submit_button and not user_input.strip():
        st.warning(" Please describe your background and learning goals before generating a study plan.")


if __name__ == "__main__":
    main()
