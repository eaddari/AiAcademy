sanitize_input:
  description: >
      Analyze the user input: "{question}"
      
      Check for:
      1. Empty or null input
      2. Excessive whitespace or formatting issues
      3. Control characters, escape sequences (like Ctrl+C, special characters)
      4. Input length and basic structure validation
      5. Proper encoding and character validation
      
      Clean and format the input appropriately while preserving meaning.
  expected_output: >
      A validation report containing:
      - List of any issues found
      - Sanitized version of the input (if applicable)
      - Recommendations for input improvement
      - The cleaned and sanitized input
  agent: input_sanitizer

check_academic_ethics:
  description: >
      Evaluate the sanitized user input for academic ethics and integrity.
      
      Assess for:
      1. Legitimate educational/research purpose
      2. No requests for plagiarism or cheating assistance
      3. No attempts to circumvent academic policies
      4. Appropriate academic level and complexity
      5. Ethical research intentions
      
      Input to evaluate: "{sanitize_input.output}"
  expected_output: >
      An ethics assessment report containing:
      - Ethics status (APPROVED/REJECTED/NEEDS_REVIEW)
      - Detailed explanation of ethical considerations
      - Any red flags or concerns identified
      - Recommendations for ethical research approach
      - Academic integrity score (1-10)
  agent: ethics_checker
  context:
    - sanitize_input

validate_security:
  description: >
      Perform security validation on the user input to detect potential threats.
      
      Screen for:
      1. Injection attempts (SQL, command injection, etc.)
      2. Social engineering patterns
      3. Attempts to access unauthorized information
      4. Malicious URLs or suspicious links
      5. Data exfiltration attempts
      6. System exploitation attempts
      
      Input to analyze: "{check_academic_ethics.output}"
  expected_output: >
      A security assessment report containing:
      - Security status (SAFE/RISKY/DANGEROUS)
      - Threat level assessment (LOW/MEDIUM/HIGH)
      - Specific security concerns identified
      - Risk mitigation recommendations
      - Safe usage guidelines
  agent: security_validator

individuate_role:
    description: >
        Based on the validated input and assessment reports, determine the most suitable
        job role for the user.

        Consider:
        1. Job role alignment with input topic if not specified in the input

        Input to consider: "{input_sanitizer.output}"
    expected_output: >
        A string of the most appropriate job role for the user, like: "Research Assistant", "Data Analyst", "Machine Learning Engineer", "Software Developer"
        "Corporate Trainer", "Project Manager", "Finance Analyst".

    agent: role_identifier

individuate_knowledge:
    description: >
        Based on the validated input and assessment reports, determine the user's current
        knowledge level in the relevant field.

        Consider:
        1. Basic, Intermediate, Advanced, Expert levels

        Input to consider: "{input_sanitizer.output}"
    expected_output: >
        A string indicating the user's current knowledge level, like: "Beginner", "Intermediate", "Advanced", "Expert"
    agent: knowledge_identifier

final_validation:
  description: >
      Compile all validation results and provide a final recommendation.
      
      Consider results from:
      1. Academic ethics evaluation
      2. Security validation

      Provide a comprehensive final decision on whether the input should be
      processed for academic research purposes.
  expected_output: >
      Return a dictionary with these structure if the validation status is APPROVED:
      {
          "role": "{individuate_role.output}",
          "current_knowledge_level": "{individuate_knowledge.output}",
      }

  agent: final_validator
  context:
    - sanitize_input
    - individuate_role
    - individuate_knowledge